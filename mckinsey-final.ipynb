{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from rfpimp import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sortedcontainers import SortedList\n",
    "import copy\n",
    "import collections\n",
    "import numpy as np\n",
    "from itertools import product, chain\n",
    "import pandas\n",
    "from sklearn.model_selection import KFold\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import scale\n",
    "# from sklearn.cross_validation import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.metrics import fbeta_score, make_scorer,recall_score,precision_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings(category=DeprecationWarning,action='ignore')\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/mckinsey/'\n",
    "\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "\n",
    "test = pd.read_csv(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(path + 'sample_submission_1.csv')\n",
    "\n",
    "train.head(1)\n",
    "\n",
    "test.head(1)\n",
    "\n",
    "train.shape\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "train.smoking_status.unique()\n",
    "\n",
    "train.work_type.unique()\n",
    "\n",
    "train.Residence_type.unique()\n",
    "\n",
    "train.groupby('stroke').size()\n",
    "\n",
    "def train_cats(df):\n",
    "    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n",
    "    catagorical values. This applies the changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "train_cats(train)\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n",
    "    a template for the category codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values. The category codes are determined by trn.\n",
    "\n",
    "    trn: A pandas dataframe. When creating a category for df, it looks up the\n",
    "        what the category's code were in trn and makes those the category codes\n",
    "        for df.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category {a : 1, b : 2}\n",
    "\n",
    "    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n",
    "    >>> apply_cats(df2, df)\n",
    "\n",
    "           col1 col2\n",
    "        0     1    b\n",
    "        1     2    a\n",
    "        2     3    a\n",
    "\n",
    "    now the type of col is category {a : 1, b : 2}\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name == 'category'):\n",
    "            df[n] = pd.Categorical(\n",
    "                c, categories=trn[n].cat.categories, ordered=True)\n",
    "\n",
    "apply_cats(test, train)\n",
    "\n",
    "train['bmi_is_na'] = 0\n",
    "\n",
    "train.loc[train.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "test['bmi_is_na'] = 0\n",
    "\n",
    "test.loc[test.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "train.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "test.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "train.dtypes\n",
    "\n",
    "test.dtypes\n",
    "\n",
    "cat_cols = [\n",
    "    'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'\n",
    "]\n",
    "\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].cat.codes\n",
    "    test[c] = test[c].cat.codes\n",
    "\n",
    "train.head()\n",
    "\n",
    "test.head()\n",
    "\n",
    "def create_submission(pred, path, fname):\n",
    "    submission = pd.DataFrame({'id': test.id, 'stroke': pred})\n",
    "    submission.to_csv(path + fname, index=False)\n",
    "\n",
    "train.shape\n",
    "\n",
    "test.shape\n",
    "\n",
    "def modelfit(alg,\n",
    "             labels,\n",
    "             predictors,\n",
    "             useTrainCV=True,\n",
    "             cv_folds=5,\n",
    "             early_stopping_rounds=50):\n",
    "\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(predictors, labels)\n",
    "        cvresult = xgb.cv(\n",
    "            xgb_param,\n",
    "            xgtrain,\n",
    "            num_boost_round=alg.get_params()['n_estimators'],\n",
    "            nfold=cv_folds,\n",
    "            metrics='auc',\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            show_stdv=True,\n",
    "            verbose_eval=True,\n",
    "            seed=4,stratified=True)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(predictors, labels)\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(predictors)\n",
    "    dtrain_predprob = alg.predict_proba(predictors)[:, 1]\n",
    "\n",
    "    #Print model report:\n",
    "#     fbeta_score = fbeta_threshold(labels, dtrain_predprob)\n",
    "#     auc_score = metrics.roc_auc_score(labels, dtrain_predprob)\n",
    "\n",
    "#     print(f\"fbeta: {fbeta_score}\")\n",
    "#     print(f\"AUC: {auc_score}\")\n",
    "\n",
    "    return alg\n",
    "\n",
    "xgb1 = xgb.XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    seed=27,\n",
    "    silent=True)\n",
    "\n",
    "x_train, y_train = train.drop('stroke', axis=1).values, train.stroke\n",
    "\n",
    "m = modelfit(xgb1,y_train,x_train,cv_folds=3)\n",
    "\n",
    "m\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "    'min_child_weight': range(1, 6, 2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=37,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid=param_test1,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        train.drop('stroke', axis=1), train.stroke),verbose=3)\n",
    "\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'min_child_weight': [4,5,6]\n",
    "}\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=37,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid=param_test1,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        train.drop('stroke', axis=1), train.stroke),verbose=3)\n",
    "\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': [3],\n",
    "    'min_child_weight': [22,24,26]\n",
    "}\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=37,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid=param_test1,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        train.drop('stroke', axis=1), train.stroke),verbose=3)\n",
    "\n",
    "gsearch1.fit(x_train, y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_\n",
    "\n",
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=37,\n",
    "        max_depth=3,\n",
    "        min_child_weight=22,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid=param_test3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        train.drop('stroke', axis=1), train.stroke),verbose=3)\n",
    "\n",
    "gsearch3.fit(x_train, y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_\n",
    "\n",
    "xgb1 = xgb.XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=22,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    seed=27,\n",
    "    silent=True)\n",
    "\n",
    "x_train, y_train = train.drop('stroke', axis=1).values, train.stroke\n",
    "\n",
    "m = modelfit(xgb1,y_train,x_train,cv_folds=3)\n",
    "\n",
    "m\n",
    "\n",
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=37,\n",
    "        max_depth=3,\n",
    "        min_child_weight=22,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid=param_test4,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        train.drop('stroke', axis=1), train.stroke),verbose=3)\n",
    "\n",
    "gsearch4.fit(x_train, y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_\n",
    "\n",
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in [85,90,95]],\n",
    " 'colsample_bytree':[i/100.0 for i in [75,80,85]]\n",
    "}\n",
    "gsearch5 = GridSearchCV(\n",
    "    estimator=xgb.XGBClassifier(\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=37,\n",
    "        max_depth=3,\n",
    "        min_child_weight=22,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27),\n",
    "    param_grid=param_test5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        train.drop('stroke', axis=1), train.stroke),verbose=3)\n",
    "\n",
    "gsearch5.fit(x_train, y_train)\n",
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_\n",
    "\n",
    "xgb1 = xgb.XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=3,\n",
    "    min_child_weight=22,\n",
    "    gamma=0,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.75,\n",
    "    objective='binary:logistic',\n",
    "    seed=27,\n",
    "    silent=True)\n",
    "\n",
    "x_train, y_train = train.drop('stroke', axis=1).values, train.stroke\n",
    "\n",
    "m = modelfit(xgb1,y_train,x_train,cv_folds=3)\n",
    "\n",
    "m\n",
    "\n",
    "m.fit(x_train,y_train)\n",
    "\n",
    "probs = m.predict_proba(test.values)[:,1]\n",
    "\n",
    "create_submission(probs,path,'xgb8.csv')\n",
    "\n",
    "m\n",
    "\n",
    "for stacking\n",
    "\n",
    "x_train, y_train = train.drop('stroke', axis=1).reset_index(drop= True), train.stroke\n",
    "\n",
    "x_test = test\n",
    "\n",
    "clf = m\n",
    "\n",
    "trn = x_train.copy()\n",
    "\n",
    "tst = x_test.copy()\n",
    "\n",
    "x_train['xgb_soft'] = 0\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, val_index in StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        x_train, y_train):\n",
    "    x_trn, y_trn = trn.loc[train_index,:], y_train[train_index]\n",
    "    x_val, y_val = trn.loc[val_index,:], y_train[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn)\n",
    "    \n",
    "    probs = clf.predict_proba(x_val)[:, 1]\n",
    "    \n",
    "    \n",
    "    x_train.loc[val_index,'xgb_soft'] = probs\n",
    "\n",
    "    \n",
    "clf.fit(trn,y_train)\n",
    "probs = clf.predict_proba(tst)[:, 1]\n",
    "\n",
    "x_test.loc[:,'xgb_soft'] = probs\n",
    "\n",
    "x_train.to_feather('data/mckinsey/stack_trn_xgb')\n",
    "\n",
    "x_test.to_feather('data/mckinsey/stack_tst_xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/mckinsey/'\n",
    "\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "sample = pd.read_csv(path + 'sample_submission_1.csv')\n",
    "\n",
    "train.head(1)\n",
    "\n",
    "test.head(1)\n",
    "\n",
    "train.shape\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "train.smoking_status.unique()\n",
    "\n",
    "train.work_type.unique()\n",
    "\n",
    "train.Residence_type.unique()\n",
    "\n",
    "train.groupby('stroke').size()\n",
    "\n",
    "def train_cats(df):\n",
    "    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n",
    "    catagorical values. This applies the changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "train_cats(train)\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n",
    "    a template for the category codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values. The category codes are determined by trn.\n",
    "\n",
    "    trn: A pandas dataframe. When creating a category for df, it looks up the\n",
    "        what the category's code were in trn and makes those the category codes\n",
    "        for df.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category {a : 1, b : 2}\n",
    "\n",
    "    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n",
    "    >>> apply_cats(df2, df)\n",
    "\n",
    "           col1 col2\n",
    "        0     1    b\n",
    "        1     2    a\n",
    "        2     3    a\n",
    "\n",
    "    now the type of col is category {a : 1, b : 2}\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name == 'category'):\n",
    "            df[n] = pd.Categorical(\n",
    "                c, categories=trn[n].cat.categories, ordered=True)\n",
    "\n",
    "apply_cats(test, train)\n",
    "\n",
    "train['bmi_is_na'] = 0\n",
    "\n",
    "train.loc[train.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "test['bmi_is_na'] = 0\n",
    "\n",
    "test.loc[test.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "train.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "test.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "train.dtypes\n",
    "\n",
    "test.dtypes\n",
    "\n",
    "cat_cols = [\n",
    "    'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'\n",
    "]\n",
    "\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].cat.codes\n",
    "    test[c] = test[c].cat.codes\n",
    "\n",
    "train.head()\n",
    "\n",
    "test.head()\n",
    "\n",
    "def create_submission(pred, path, fname):\n",
    "    submission = pd.DataFrame({'id': test.id, 'stroke': pred})\n",
    "    submission.to_csv(path + fname, index=False)\n",
    "\n",
    "train.shape\n",
    "\n",
    "test.shape\n",
    "\n",
    "### without class weight balanced\n",
    "\n",
    "all features considered\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=50,\n",
    "    oob_score=False,\n",
    "    min_samples_leaf=3)\n",
    "\n",
    "grid = {\n",
    "    'min_samples_leaf': [200,230,250],\n",
    "    'max_features': ['auto']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    model,\n",
    "    grid,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        train.drop('stroke', axis=1), train.stroke),\n",
    "    scoring='roc_auc',\n",
    "    verbose=5)\n",
    "\n",
    "clf.fit(train.drop('stroke', axis=1), train.stroke)\n",
    "\n",
    "clf.best_score_\n",
    "\n",
    "clf.best_params_\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_jobs=-1,\n",
    "    n_estimators=200,\n",
    "    min_samples_leaf=200,\n",
    "    max_features='auto',\n",
    "    oob_score=True)\n",
    "\n",
    "rf.fit(train.drop('stroke', axis=1), train.stroke)\n",
    "\n",
    "probs = rf.predict_proba(test)[:,1]\n",
    "\n",
    "create_submission(probs,path,'rfv5.csv')\n",
    "\n",
    "feature selection\n",
    "\n",
    "cols_to_keep = ['heart_disease', 'id', 'bmi', 'avg_glucose_level', 'age','hypertension']\n",
    "\n",
    "x_train,y_train = train.loc[:,cols_to_keep], train.stroke\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=50,\n",
    "    oob_score=False,\n",
    "    min_samples_leaf=3)\n",
    "\n",
    "grid = {\n",
    "    'min_samples_leaf': [200,230,250],\n",
    "    'max_features': ['auto','log2',None,0.5]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    model,\n",
    "    grid,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        x_train, y_train),\n",
    "    scoring='roc_auc',\n",
    "    verbose=5)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf.best_score_\n",
    "\n",
    "clf.best_params_\n",
    "\n",
    "cv score is not improving\n",
    "\n",
    "without stratification\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=50,\n",
    "    oob_score=False,\n",
    "    min_samples_leaf=3)\n",
    "\n",
    "grid = {\n",
    "    'min_samples_leaf': [100,150,200,230,250],\n",
    "    'max_features': ['auto']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    model,\n",
    "    grid,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    verbose=5)\n",
    "\n",
    "clf.fit(train.drop('stroke', axis=1), train.stroke)\n",
    "\n",
    "clf.best_score_\n",
    "\n",
    "clf.best_params_\n",
    "\n",
    "### Ensembling\n",
    "\n",
    "xgb = pd.read_csv('data/mckinsey/xgb_ens.csv')\n",
    "\n",
    "rf = pd.read_csv('data/mckinsey/rf_ens.csv')\n",
    "\n",
    "lgb = pd.read_csv('data/mckinsey/lgb_ens.csv')\n",
    "\n",
    "cb = pd.read_csv('data/mckinsey/cat_ens.csv')\n",
    "\n",
    "plt.hist(xgb.stroke)\n",
    "\n",
    "plt.hist(rf.stroke)\n",
    "\n",
    "plt.hist(lgb.stroke)\n",
    "\n",
    "plt.hist(cb.stroke)\n",
    "\n",
    "pred = (rf.stroke+xgb.stroke+cb.stroke+lgb.stroke)/4\n",
    "\n",
    "create_submission(pred,path,'ensemble_4.csv')\n",
    "\n",
    "for stacking\n",
    "\n",
    "x_train, y_train = train.drop('stroke', axis=1).reset_index(drop= True), train.stroke\n",
    "\n",
    "x_test = test\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_jobs=-1,\n",
    "    n_estimators=200,\n",
    "    min_samples_leaf=200,\n",
    "    max_features='auto',\n",
    "    oob_score=True)\n",
    "\n",
    "trn = x_train.copy()\n",
    "\n",
    "tst = x_test.copy()\n",
    "\n",
    "x_train['rf_soft'] = 0\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, val_index in StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        x_train, y_train):\n",
    "    x_trn, y_trn = trn.loc[train_index,:], y_train[train_index]\n",
    "    x_val, y_val = trn.loc[val_index,:], y_train[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn)\n",
    "    \n",
    "    probs = clf.predict_proba(x_val)[:, 1]\n",
    "    \n",
    "    \n",
    "    x_train.loc[val_index,'rf_soft'] = probs\n",
    "\n",
    "    \n",
    "clf.fit(trn,y_train)\n",
    "probs = clf.predict_proba(tst)[:, 1]\n",
    "\n",
    "x_test.loc[:,'rf_soft'] = probs\n",
    "\n",
    "x_train.to_feather('data/mckinsey/stack_trn_rf')\n",
    "\n",
    "x_test.to_feather('data/mckinsey/stack_tst_rf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/mckinsey/'\n",
    "\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "sample = pd.read_csv(path + 'sample_submission_1.csv')\n",
    "\n",
    "train.head(1)\n",
    "\n",
    "test.head(1)\n",
    "\n",
    "train.shape\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "train.smoking_status.unique()\n",
    "\n",
    "train.work_type.unique()\n",
    "\n",
    "train.Residence_type.unique()\n",
    "\n",
    "train.groupby('stroke').size()\n",
    "\n",
    "def train_cats(df):\n",
    "    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n",
    "    catagorical values. This applies the changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "train_cats(train)\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n",
    "    a template for the category codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values. The category codes are determined by trn.\n",
    "\n",
    "    trn: A pandas dataframe. When creating a category for df, it looks up the\n",
    "        what the category's code were in trn and makes those the category codes\n",
    "        for df.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category {a : 1, b : 2}\n",
    "\n",
    "    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n",
    "    >>> apply_cats(df2, df)\n",
    "\n",
    "           col1 col2\n",
    "        0     1    b\n",
    "        1     2    a\n",
    "        2     3    a\n",
    "\n",
    "    now the type of col is category {a : 1, b : 2}\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name == 'category'):\n",
    "            df[n] = pd.Categorical(\n",
    "                c, categories=trn[n].cat.categories, ordered=True)\n",
    "\n",
    "apply_cats(test, train)\n",
    "\n",
    "train['bmi_is_na'] = 0\n",
    "\n",
    "train.loc[train.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "test['bmi_is_na'] = 0\n",
    "\n",
    "test.loc[test.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "train.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "test.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "train.dtypes\n",
    "\n",
    "test.dtypes\n",
    "\n",
    "cat_cols = [\n",
    "    'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'\n",
    "]\n",
    "\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].cat.codes\n",
    "    test[c] = test[c].cat.codes\n",
    "\n",
    "train.head()\n",
    "\n",
    "test.head()\n",
    "\n",
    "def create_submission(pred, path, fname):\n",
    "    submission = pd.DataFrame({'id': test.id, 'stroke': pred})\n",
    "    submission.to_csv(path + fname, index=False)\n",
    "\n",
    "train.shape\n",
    "\n",
    "test.shape\n",
    "\n",
    "lg = lgb.LGBMClassifier(learning_rate=0.05, num_leaves=10, max_depth=15, subsample=0.8, n_estimators=100, )\n",
    "\n",
    "lg.fit(train.drop('stroke', axis=1), train.stroke)\n",
    "\n",
    "probs = lg.predict_proba(test)[:,1]\n",
    "\n",
    "create_submission(probs,path,'lgb1.csv')\n",
    "\n",
    "lg\n",
    "\n",
    "### for stacking\n",
    "\n",
    "x_train, y_train = train.drop('stroke', axis=1).reset_index(drop= True), train.stroke\n",
    "\n",
    "x_test = test\n",
    "\n",
    "clf = lg\n",
    "\n",
    "trn = x_train.copy()\n",
    "\n",
    "tst = x_test.copy()\n",
    "\n",
    "x_train['lgb_soft'] = 0\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, val_index in StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        x_train, y_train):\n",
    "    x_trn, y_trn = trn.loc[train_index,:], y_train[train_index]\n",
    "    x_val, y_val = trn.loc[val_index,:], y_train[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn)\n",
    "    \n",
    "    probs = clf.predict_proba(x_val)[:, 1]\n",
    "    \n",
    "    \n",
    "    x_train.loc[val_index,'lgb_soft'] = probs\n",
    "\n",
    "    \n",
    "clf.fit(trn,y_train)\n",
    "probs = clf.predict_proba(tst)[:, 1]\n",
    "\n",
    "x_test.loc[:,'lgb_soft'] = probs\n",
    "\n",
    "x_train.to_feather('data/mckinsey/stack_trn_lgb')\n",
    "\n",
    "x_test.to_feather('data/mckinsey/stack_tst_lgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(pred, path, fname):\n",
    "    submission = pd.DataFrame({'id': test.id, 'stroke': pred})\n",
    "    submission.to_csv(path + fname, index=False)\n",
    "\n",
    "path = 'data/mckinsey/'\n",
    "\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "sample = pd.read_csv(path + 'sample_submission_1.csv')\n",
    "\n",
    "train.head(1)\n",
    "\n",
    "test.head(1)\n",
    "\n",
    "train.shape\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "train.smoking_status.unique()\n",
    "\n",
    "train.work_type.unique()\n",
    "\n",
    "train.Residence_type.unique()\n",
    "\n",
    "train.groupby('stroke').size()\n",
    "\n",
    "def train_cats(df):\n",
    "    \"\"\"Change any columns of strings in a panda's dataframe to a column of\n",
    "    catagorical values. This applies the changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "train_cats(train)\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    \"\"\"Changes any columns of strings in df into categorical variables using trn as\n",
    "    a template for the category codes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas dataframe. Any columns of strings will be changed to\n",
    "        categorical values. The category codes are determined by trn.\n",
    "\n",
    "    trn: A pandas dataframe. When creating a category for df, it looks up the\n",
    "        what the category's code were in trn and makes those the category codes\n",
    "        for df.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n",
    "    >>> df\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    note the type of col2 is string\n",
    "\n",
    "    >>> train_cats(df)\n",
    "    >>> df\n",
    "\n",
    "       col1 col2\n",
    "    0     1    a\n",
    "    1     2    b\n",
    "    2     3    a\n",
    "\n",
    "    now the type of col2 is category {a : 1, b : 2}\n",
    "\n",
    "    >>> df2 = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['b', 'a', 'a']})\n",
    "    >>> apply_cats(df2, df)\n",
    "\n",
    "           col1 col2\n",
    "        0     1    b\n",
    "        1     2    a\n",
    "        2     3    a\n",
    "\n",
    "    now the type of col is category {a : 1, b : 2}\n",
    "    \"\"\"\n",
    "    for n, c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name == 'category'):\n",
    "            df[n] = pd.Categorical(\n",
    "                c, categories=trn[n].cat.categories, ordered=True)\n",
    "\n",
    "apply_cats(test, train)\n",
    "\n",
    "train['bmi_is_na'] = 0\n",
    "\n",
    "train.loc[train.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "test['bmi_is_na'] = 0\n",
    "\n",
    "test.loc[test.bmi.isna(),'bmi_is_na'] = 1\n",
    "\n",
    "train.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "test.bmi.fillna(train.bmi[train.bmi.notnull()].median(), inplace=True)\n",
    "\n",
    "train.dtypes\n",
    "\n",
    "test.dtypes\n",
    "\n",
    "cat_cols = [\n",
    "    'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'\n",
    "]\n",
    "\n",
    "for c in cat_cols:\n",
    "    train[c] = train[c].cat.codes\n",
    "    test[c] = test[c].cat.codes\n",
    "\n",
    "#### Catboost\n",
    "\n",
    "train.dtypes\n",
    "\n",
    "x_train,y_train = train.drop('stroke',axis=1), train.stroke\n",
    "\n",
    "cat_cols_index = np.where(x_train.dtypes != \"float\")[0]\n",
    "\n",
    "cat_cols_index\n",
    "\n",
    "from sortedcontainers import SortedList\n",
    "import copy\n",
    "import collections\n",
    "import numpy as np\n",
    "from itertools import product, chain\n",
    "import pandas\n",
    "from sklearn.model_selection import KFold\n",
    "import catboost as cb\n",
    "''' a class for doing grid search on a set of parameters provided in a dict. 'pdict' should be a dictionary like the following:\n",
    "pdict = {'depth':[1,2], 'iterations':[250,100,500], 'thread_count':4}\n",
    "\n",
    "when grid_search is called it will return an iterator that provides samples from the dictionary e.g.\n",
    "{'depth':1, 'iterations':250, 'thread_count':4}\n",
    "{'depth':2, 'iterations':250, 'thread_count':4}\n",
    "{'depth':1, 'iterations':100, 'thread_count':4}\n",
    "etc.\n",
    "after calling an iteration of grid_search, you need to test the classifier and run 'register_result'\n",
    "This will update the internal list of results, so that the next call to grid_search will use the best\n",
    "parameters for all the parameters not currently being updated.\n",
    "\n",
    "grid_search can be provided a list e.g. grid_search(['depth']) this will use the current best parameters for all\n",
    "the other arguments and only search over 'depth'. You can then call e.g. grid_search(['iterations']) and it will use\n",
    "the best depth found previously and cycle through all the 'iterations'. Searching incrementally can be much faster\n",
    "than doing a full grid search, but may miss the global optimum. '''\n",
    "\n",
    "\n",
    "class paramsearch:\n",
    "    def __init__(self, pdict):\n",
    "        self.pdict = {}\n",
    "        # if something is not passed in as a sequence, make it a sequence with 1 element\n",
    "        #   don't treat strings as sequences\n",
    "        for a, b in pdict.items():\n",
    "            if isinstance(b, collections.Sequence) and not isinstance(b, str):\n",
    "                self.pdict[a] = b\n",
    "            else:\n",
    "                self.pdict[a] = [b]\n",
    "        # our results are a sorted list, so the best score is always the final element\n",
    "        self.results = SortedList()\n",
    "\n",
    "    def grid_search(self, keys=None):\n",
    "        # do grid search on only the keys listed. If none provided, do all\n",
    "        if keys == None: keylist = self.pdict.keys()\n",
    "        else: keylist = keys\n",
    "\n",
    "        listoflists = []  # this will be list of lists of key,value pairs\n",
    "        for key in keylist:\n",
    "            listoflists.append([(key, i) for i in self.pdict[key]])\n",
    "        for p in product(*listoflists):\n",
    "            # do any changes to the current best parameter set\n",
    "            if len(self.results) > 0: template = self.results[-1][1]\n",
    "            else: template = {a: b[0] for a, b in self.pdict.items()}\n",
    "            # if our updates are the same as current best, don't bother\n",
    "            if self.equaldict(dict(p), template): continue\n",
    "            # take the current best and update just the ones to change\n",
    "            yield self.overwritedict(dict(p), template)\n",
    "\n",
    "    def equaldict(self, a, b):\n",
    "        for key in a.keys():\n",
    "            if a[key] != b[key]: return False\n",
    "        return True\n",
    "\n",
    "    def overwritedict(self, new, old):\n",
    "        old = copy.deepcopy(old)\n",
    "        for key in new.keys():\n",
    "            old[key] = new[key]\n",
    "        return old\n",
    "\n",
    "    # save a (score,params) pair to results. Since 'results' is a sorted list,\n",
    "    #   the best score is always the final element. A small amount of noise is added\n",
    "    #   because sorted lists don't like it when two scores are exactly the same\n",
    "    def register_result(self, result, params):\n",
    "        self.results.add((result + np.random.randn() * 1e-10, params))\n",
    "\n",
    "    def bestscore(self):\n",
    "        return self.results[-1][0]\n",
    "\n",
    "    def bestparam(self):\n",
    "        return self.results[-1][1]\n",
    "\n",
    "\n",
    "params = {\n",
    "    'depth': [1, 3, 5],\n",
    "    'l2_leaf_reg': [1, 4, 9],\n",
    "    'iterations': [100],\n",
    "    'learning_rate': [0.05, 0.08, 0.09, 0.1],\n",
    "    \"one_hot_max_size\": [10]\n",
    "}\n",
    "\n",
    "\n",
    "# this function does 3-fold crossvalidation with catboostclassifier\n",
    "def crossvaltest(params, train_set, train_label, cat_dims, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    res = []\n",
    "    for train_index, test_index in kf.split(train_set):\n",
    "        train = train_set.iloc[train_index, :]\n",
    "        test = train_set.iloc[test_index, :]\n",
    "\n",
    "        labels = train_label.ix[train_index]\n",
    "        test_labels = train_label.ix[test_index]\n",
    "\n",
    "        clf = cb.CatBoostClassifier(**params)\n",
    "        clf.fit(train, np.ravel(labels), cat_features=cat_dims)\n",
    "\n",
    "        res.append(np.mean(clf.predict(test) == np.ravel(test_labels)))\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def catboost_param_tune(params,\n",
    "                        train_set,\n",
    "                        train_label,\n",
    "                        cat_dims=None,\n",
    "                        n_splits=5):\n",
    "    ps = paramsearch(params)\n",
    "    # search 'border_count', 'l2_leaf_reg' etc. individually\n",
    "    #   but 'iterations','learning_rate' together\n",
    "    for prms in chain(\n",
    "            ps.grid_search(['iterations', 'learning_rate']),\n",
    "            ps.grid_search(['one_hot_max_size'])):\n",
    "        res = crossvaltest(prms, train_set, train_label, cat_dims, n_splits)\n",
    "        # save the crossvalidation result so that future iterations can reuse the best parameters\n",
    "        ps.register_result(res, prms)\n",
    "        print(res, prms, 'best:', ps.bestscore(), ps.bestparam())\n",
    "    return ps.bestparam()\n",
    "\n",
    "\n",
    "bestparams = catboost_param_tune(\n",
    "    params, x_train, y_train, cat_dims=cat_cols_index)\n",
    "\n",
    "bestparams\n",
    "\n",
    "clf = cb.CatBoostClassifier(eval_metric=\"AUC\",one_hot_max_size=10, \\\n",
    "                        depth=1, iterations= 100, l2_leaf_reg= 1, learning_rate= 0.09)\n",
    "clf.fit(x_train,y_train, cat_features=cat_cols_index)\n",
    "\n",
    "probs = clf.predict_proba(test)[:,1]\n",
    "\n",
    "np.mean(probs)\n",
    "\n",
    "np.mean(probs>0.5)\n",
    "\n",
    "create_submission(probs,path,'cb2.csv')\n",
    "\n",
    "\n",
    "\n",
    "test.head()\n",
    "\n",
    "x_train, y_train = train.drop('stroke', axis=1).reset_index(drop= True), train.stroke\n",
    "\n",
    "x_test = test\n",
    "\n",
    "clf = cb.CatBoostClassifier(eval_metric=\"AUC\",one_hot_max_size=10, \\\n",
    "                        depth=1, iterations= 100, l2_leaf_reg= 1, learning_rate= 0.09)\n",
    "\n",
    "trn = x_train.copy()\n",
    "\n",
    "tst = x_test.copy()\n",
    "\n",
    "x_train['cat_soft'] = 0\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for train_index, val_index in StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        x_train, y_train):\n",
    "    x_trn, y_trn = trn.loc[train_index,:], y_train[train_index]\n",
    "    x_val, y_val = trn.loc[val_index,:], y_train[val_index]\n",
    "\n",
    "    clf.fit(x_trn, y_trn,cat_features=cat_cols_index)\n",
    "    \n",
    "    probs = clf.predict_proba(x_val)[:, 1]\n",
    "    \n",
    "    \n",
    "    x_train.loc[val_index,'cat_soft'] = probs\n",
    "\n",
    "    \n",
    "clf.fit(trn,y_train)\n",
    "probs = clf.predict_proba(tst)[:, 1]\n",
    "\n",
    "x_test.loc[:,'cat_soft'] = probs\n",
    "\n",
    "x_train.to_feather('data/mckinsey/stack_trn_cat')\n",
    "\n",
    "x_test.to_feather('data/mckinsey/stack_tst_cat')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_trn = pd.read_feather('data/mckinsey/stack_trn_rf')\n",
    "\n",
    "rf_tst = pd.read_feather('data/mckinsey/stack_tst_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_trn = pd.read_feather('data/mckinsey/stack_trn_xgb')\n",
    "\n",
    "xgb_tst = pd.read_feather('data/mckinsey/stack_tst_xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_trn = pd.read_feather('data/mckinsey/stack_trn_lgb')\n",
    "\n",
    "lgb_tst = pd.read_feather('data/mckinsey/stack_tst_lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_trn = pd.read_feather('data/mckinsey/stack_trn_cat')\n",
    "\n",
    "cat_tst = pd.read_feather('data/mckinsey/stack_tst_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_final = rf_trn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_final = rf_tst.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_final = trn_final.assign(xgb_soft = xgb_trn.xgb_soft,cat_soft = cat_trn.cat_soft,lgb_soft = lgb_trn.lgb_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_final = tst_final.assign(xgb_soft = xgb_tst.xgb_soft,cat_soft = cat_tst.cat_soft,lgb_soft = lgb_tst.lgb_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_final['stroke'] = train.stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>bmi_is_na</th>\n",
       "      <th>rf_soft</th>\n",
       "      <th>xgb_soft</th>\n",
       "      <th>cat_soft</th>\n",
       "      <th>lgb_soft</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30669</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>95.12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30468</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.031925</td>\n",
       "      <td>0.031090</td>\n",
       "      <td>0.024035</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16523</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>110.89</td>\n",
       "      <td>17.6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56543</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026802</td>\n",
       "      <td>0.033358</td>\n",
       "      <td>0.030217</td>\n",
       "      <td>0.032060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46136</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>161.28</td>\n",
       "      <td>19.1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0  30669       1   3.0             0              0             0          4   \n",
       "1  30468       1  58.0             1              0             1          2   \n",
       "2  16523       0   8.0             0              0             0          2   \n",
       "3  56543       0  70.0             0              0             1          2   \n",
       "4  46136       1  14.0             0              0             0          1   \n",
       "\n",
       "   Residence_type  avg_glucose_level   bmi  smoking_status  bmi_is_na  \\\n",
       "0               0              95.12  18.0              -1          0   \n",
       "1               1              87.96  39.2               1          0   \n",
       "2               1             110.89  17.6              -1          0   \n",
       "3               0              69.04  35.9               0          0   \n",
       "4               0             161.28  19.1              -1          0   \n",
       "\n",
       "    rf_soft  xgb_soft  cat_soft  lgb_soft  stroke  \n",
       "0  0.000064  0.004896  0.002196  0.003997       0  \n",
       "1  0.031925  0.031090  0.024035  0.028025       0  \n",
       "2  0.000847  0.005516  0.001527  0.004317       0  \n",
       "3  0.026802  0.033358  0.030217  0.032060       0  \n",
       "4  0.002722  0.005769  0.002361  0.004060       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
       "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
       "       'smoking_status', 'bmi_is_na', 'rf_soft', 'xgb_soft', 'cat_soft',\n",
       "       'lgb_soft', 'stroke'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = trn_final.loc[:,['rf_soft', 'xgb_soft', 'cat_soft','lgb_soft']],trn_final.stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tst_final.loc[:,['rf_soft', 'xgb_soft', 'cat_soft','lgb_soft']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8578249004926417, total=   0.4s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8624255144472439, total=   0.4s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.877546220436655, total=   0.4s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.8570853716226969, total=   0.5s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.8622415761943985, total=   0.4s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.8772875559169846, total=   0.5s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=None .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8566508781837905, total=   0.5s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=None .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.862490513155361, total=   0.6s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=None .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8774736649040257, total=   0.4s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8578246307884586, total=   1.0s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.862425784151427, total=   1.1s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8775470296061638, total=   1.0s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.856932719055086, total=   1.3s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.862397465212206, total=   1.4s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.877367124252024, total=   1.2s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8566775788979132, total=   1.0s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8624621942161399, total=   1.1s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.877397333247022, total=   1.1s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8578243610842755, total=   2.1s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.862425784151427, total=   2.3s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8775467598829941, total=   2.2s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.8568550442503653, total=   2.2s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.862342175854679, total=   2.1s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.8774256541798325, total=   2.1s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8564944497576168, total=   2.0s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8624363026145663, total=   2.2s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8774035368799232, total=   2.0s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 ......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8578249004926417, total=   4.3s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 ......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8624263235597931, total=   3.6s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 ......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8775470296061638, total=   3.7s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 ......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.8567752118121801, total=   5.7s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 ......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.8623351635459195, total=   5.3s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 ......\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.8773838470885407, total=   5.6s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=None ....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8565211504717396, total=   3.8s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=None ....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8623928802410938, total=   3.9s\n",
      "[CV] alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=None ....\n",
      "[CV]  alpha=0.0001, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8773803406873356, total=   4.5s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8579174090274305, total=   0.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8623675280478864, total=   0.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8775160114416569, total=   0.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.8566024662829316, total=   0.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.8548956433604493, total=   0.5s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.5, total=   0.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8578346098432318, total=   0.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8623076537192478, total=   0.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8775427140354497, total=   0.5s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8579171393232474, total=   1.2s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8623675280478864, total=   1.2s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8775160114416569, total=   1.1s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.5, total=   1.3s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.8548956433604493, total=   1.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.872446294745388, total=   1.3s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8578440494896387, total=   1.1s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8623764282859274, total=   1.1s\n",
      "[CV] alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8774844538308108, total=   1.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8579171393232474, total=   2.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8623672583437034, total=   2.6s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l2 ........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8775160114416569, total=   2.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.8566024662829316, total=   2.5s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.8548956433604493, total=   2.2s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.5, total=   2.1s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8578391948143438, total=   1.9s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8623300391664415, total=   1.9s\n",
      "[CV] alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8775454112671459, total=   2.4s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8579171393232474, total=   4.0s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8623675280478864, total=   3.6s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 .......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8775160114416569, total=   3.9s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.8566024662829316, total=   4.2s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.2s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 .......\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.9s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.857831643097218, total=   3.5s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8624481695986208, total=   3.6s\n",
      "[CV] alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=None .....\n",
      "[CV]  alpha=0.001, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8775615946573234, total=   3.8s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8579228031110917, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8623688765688019, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8775170903343353, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.5, total=   0.5s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.5, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.5, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8579306245324004, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8621657893189592, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8774944335880868, total=   0.4s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8579228031110917, total=   0.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8623688765688019, total=   1.0s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8775170903343353, total=   0.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.5, total=   1.0s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.5, total=   1.1s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.5, total=   1.0s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.857915251393966, total=   0.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8623437940797773, total=   0.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8774855327234892, total=   0.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8579228031110917, total=   1.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8623688765688019, total=   1.8s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8775170903343353, total=   1.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.5, total=   2.1s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.5, total=   2.2s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.5, total=   2.1s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8579333215742309, total=   1.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8623626733725915, total=   2.0s\n",
      "[CV] alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8774790593674183, total=   2.3s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8579228031110917, total=   4.8s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8623686068646187, total=   3.9s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 ........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8775170903343353, total=   4.0s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.6s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 ........\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.5s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 ........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.6s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8579203757734442, total=   4.2s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8622636919374091, total=   4.3s\n",
      "[CV] alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=None ......\n",
      "[CV]  alpha=0.01, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8774723162881777, total=   4.3s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.857929006307302, total=   0.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.862359976330761, total=   0.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l2, score=0.8775087289160769, total=   0.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.5, total=   0.5s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.5, total=   0.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=l1, score=0.5, total=   0.5s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.858078422424716, total=   0.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.14539240070705647, total=   0.5s\n",
      "[CV] alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=100, n_jobs=-1, penalty=None, score=0.8772352296220775, total=   0.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8579265789696544, total=   1.1s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8623588975140286, total=   1.1s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l2, score=0.8775073803002289, total=   1.1s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.5, total=   1.2s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.5, total=   1.0s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=l1, score=0.5, total=   1.2s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8579438400373702, total=   1.0s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8618291984985029, total=   0.9s\n",
      "[CV] alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=250, n_jobs=-1, penalty=None, score=0.8773862745970673, total=   0.9s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8579276577863868, total=   2.0s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8623675280478865, total=   2.0s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l2 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l2, score=0.8775084591929074, total=   2.3s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.5, total=   2.3s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.5, total=   2.7s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l1 ..........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=l1, score=0.5, total=   2.2s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8579079693810234, total=   2.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.8621487979554265, total=   2.0s\n",
      "[CV] alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=None ........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=500, n_jobs=-1, penalty=None, score=0.877515202272148, total=   1.7s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8579284668989359, total=   4.4s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8623675280478866, total=   3.7s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l2 .........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l2, score=0.8775089986392467, total=   3.9s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.5s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.2s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l1 .........\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=l1, score=0.5, total=   4.2s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8579921170861375, total=   3.6s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8605866713271549, total=   3.5s\n",
      "[CV] alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=None .......\n",
      "[CV]  alpha=0.1, loss=log, n_iter=1000, n_jobs=-1, penalty=None, score=0.8769682036841487, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed:  4.8min finished\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier() # faster than vanilla logit \n",
    "\n",
    "grid = {\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1], # learning rate\n",
    "    'n_iter': [100, 250, 500, 1000], # number of epochs\n",
    "    'loss': ['log'], # logistic regression,\n",
    "    'penalty': ['l2', 'l1', 'None'],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "grid_obj = GridSearchCV(clf, grid, \n",
    "                        scoring='roc_auc',\n",
    "                        verbose=10,\n",
    "                        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(\n",
    "        x_train, y_train),\n",
    "                        iid = False) \n",
    "\n",
    "grid_obj = grid_obj.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_obj.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=1000,\n",
       "       n_jobs=-1, penalty='None', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(pred, path, fname):\n",
    "    submission = pd.DataFrame({'id': test.id, 'stroke': pred})\n",
    "    submission.to_csv(path + fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/mckinsey/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(probs,path,'stack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
